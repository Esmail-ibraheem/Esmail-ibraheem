**About Me** AI Research Engineer with a deep passion for neural networks, large language models, and cutting-edge machine 
learning techniques. Skilled in designing and optimizing scalable systems with a strong foundation in PyTorch 
and CUDA. Committed to open-source development, multilingual AI accessibility, and building intuitive tools
that bridge the gap between research and real-world applications by translating them into practical implementations.                      

**For more, check out my [website](https://esmail-ibraheem.github.io/)**   

### **Publications:** _ordered by most proud of_
1. **[ExpertRAG: Efficient RAG with Mixture of Experts -- Optimizing Context Retrieval for Adaptive LLM Responses ](https://arxiv.org/abs/2504.08744)**
2. **[Galvatron: Automatic Distributed Training for Large Transformer Models](https://arxiv.org/abs/2504.03662)**
3. **[Theoretical Foundations and Mitigation of Hallucination in Large Language Models ](https://arxiv.org/abs/2507.22915)**
4. **[Mixture of Transformers: Macro-Level Gating for Sparse Activation in Large Language Model Ensembles](http://dx.doi.org/10.13140/RG.2.2.25049.02400)**
5. **[Bachelor Thesis: AI Engine: Deep Learning and Neural Network Engine](http://dx.doi.org/10.13140/RG.2.2.22814.24643)**
6. **[Universal Approximation Theorem for a Single-Layer Transformer](https://arxiv.org/abs/2507.10581)**

 
<!--
**Esmail-ibraheem/Esmail-ibraheem** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
